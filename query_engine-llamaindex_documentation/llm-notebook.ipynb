{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:46:17.868336Z",
     "start_time": "2024-02-27T09:46:17.863360Z"
    }
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import openai\n",
    "import os\n",
    "from llama_index.core import (VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage)\n",
    "\n",
    "\"\"\"\n",
    "Setup\n",
    "\"\"\"\n",
    "dotenv.load_dotenv('../.env')\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Starter Tutorial\n",
      "\n",
      "```{tip}\n",
      "Make sure you've followed the [installation](installation.md) steps first.\n",
      "```\n",
      "Here is a starter example for using LlamaIndex. \n",
      "\n",
      "### Download\n",
      "\n",
      "LlamaIndex examples can be found in the `examples` folder of the LlamaIndex repository.\n",
      "We first want to download this `examples` folder. An easy way to do this is to just clone the repo:\n",
      "\n",
      "```bash\n",
      "$ git clone https://github.com/jerryjliu/llama_index.git\n",
      "```\n",
      "\n",
      "Next, navigate to your newly-cloned repository, and verify the contents:\n",
      "\n",
      "```bash\n",
      "$ cd llama_index\n",
      "$ ls\n",
      "LICENSE                data_requirements.txt  tests/\n",
      "MANIFEST.in            examples/              pyproject.toml\n",
      "Makefile               experimental/          requirements.txt\n",
      "README.md              llama_index/             setup.py\n",
      "```\n",
      "\n",
      "We now want to navigate to the following folder:\n",
      "\n",
      "```bash\n",
      "$ cd examples/paul_graham_essay\n",
      "```\n",
      "\n",
      "This contains LlamaIndex examples around Paul Graham's essay, [\"What I Worked On\"](http://paulgraham.com/worked.html). A comprehensive set of examples are already provided in `TestEssay.ipynb`. For the purposes of this tutorial, we can focus on a simple example of getting LlamaIndex up and running.\n",
      "\n",
      "### Build and Query Index\n",
      "\n",
      "Create a new `.py` file with the following:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```\n",
      "\n",
      "This builds an index over the documents in the `data` folder (which in this case just consists of the essay text). We then run the following\n",
      "\n",
      "```python\n",
      "query_engine = index.as_query_engine()\n",
      "response = query_engine.query(\"What did the author do growing up?\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "You should get back a response similar to the following: `The author wrote short stories and tried to program on an IBM 1401.`\n",
      "\n",
      "### Viewing Queries and Events Using Logging\n",
      "\n",
      "In a Jupyter notebook, you can view info and/or debugging logging using the following snippet:\n",
      "\n",
      "```python\n",
      "import logging\n",
      "import sys\n",
      "\n",
      "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
      "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
      "```\n",
      "\n",
      "You can set the level to `DEBUG` for verbose output, or use `level=logging.INFO` for less.\n",
      "\n",
      "### Saving and Loading\n",
      "\n",
      "By default, data is stored in-memory.\n",
      "To persist to disk (under `./storage`):\n",
      "\n",
      "```python\n",
      "index.storage_context.persist()\n",
      "```\n",
      "\n",
      "To reload from disk:\n",
      "```python\n",
      "from llama_index import StorageContext, load_index_from_storage\n",
      "\n",
      "# rebuild storage context\n",
      "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
      "# load index\n",
      "index = load_index_from_storage(storage_context)\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "```{admonition} Next Steps\n",
      "* learn more about the [high-level concepts](/getting_started/concepts.md).\n",
      "* tell me how to [customize things](/getting_started/customization.rst).\n",
      "* curious about a specific module? check out the guides ðŸ‘ˆ\n",
      "* have a use case in mind? check out the [end-to-end tutorials](/end_to_end_tutorials/use_cases.md)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "with open('./data/docs/getting_started/starter_example.md') as f:\n",
    "    text = f.read()\n",
    "    print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:35:10.570903Z",
     "start_time": "2024-02-27T09:35:10.562912Z"
    }
   },
   "id": "42c770f292478263",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-0613', temperature=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:46:21.210403Z",
     "start_time": "2024-02-27T09:46:21.197485Z"
    }
   },
   "id": "69487a15fbce957f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import Prompt\n",
    "\n",
    "text_qa_template = Prompt(\n",
    "    \"Context information is below.\\n\"\n",
    "    \"------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "refine_template = Prompt(\n",
    "    \"We have the opportunity to refine the original answer \"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"----------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"----------\\n\"\n",
    "    \"Given the new context, refine the original answer to better \"\n",
    "    \"answer the question: {query_str}. \"\n",
    "    \"If the context isn't useful, output the original answer again.\\n\"\n",
    "    \"Original Answer: {existing_answer}\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:46:23.557345Z",
     "start_time": "2024-02-27T09:46:23.548501Z"
    }
   },
   "id": "77560edb45620a19",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To install LlamaIndex, you need to follow the installation steps provided in the \"installation.md\" file.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I install llama-index?\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:46:25.995863Z",
     "start_time": "2024-02-27T09:46:24.640810Z"
    }
   },
   "id": "3bc9d4ada98f38fc",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an index using LlamaIndex, you need to follow these steps:\n",
      "\n",
      "1. Download the LlamaIndex repository by cloning it from GitHub using the command: `$ git clone https://github.com/jerryjliu/llama_index.git`.\n",
      "\n",
      "2. Navigate to the downloaded repository using the command: `$ cd llama_index`.\n",
      "\n",
      "3. Go to the `examples/paul_graham_essay` folder using the command: `$ cd examples/paul_graham_essay`.\n",
      "\n",
      "4. Create a new Python file and import the necessary classes from LlamaIndex:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "```\n",
      "\n",
      "5. Load the documents that you want to index using the `SimpleDirectoryReader` class:\n",
      "\n",
      "```python\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "```\n",
      "\n",
      "6. Build the index using the `VectorStoreIndex` class:\n",
      "\n",
      "```python\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```\n",
      "\n",
      "7. You can now use the index to query the documents. For example:\n",
      "\n",
      "```python\n",
      "query_engine = index.as_query_engine()\n",
      "response = query_engine.query(\"What did the author do growing up?\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "This will return a response based on the query.\n",
      "\n",
      "Note: The above steps assume that you have already installed LlamaIndex and have the necessary data files in the `data` folder.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do create an index?\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:48:58.335464Z",
     "start_time": "2024-02-27T09:48:52.815317Z"
    }
   },
   "id": "34307383863e2843",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```"
     ]
    }
   ],
   "source": [
    "question = \"How do I create an index? Write your answer using only code.\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response_gen = llm.stream_complete(prompt)\n",
    "for response in response_gen:\n",
    "    print(response.delta, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:49:57.016629Z",
     "start_time": "2024-02-27T09:49:55.662041Z"
    }
   },
   "id": "1441e1fffb0d31eb",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an index using LlamaIndex, you need to follow these steps:\n",
      "\n",
      "1. Download the LlamaIndex repository by cloning it from GitHub using the command: `$ git clone https://github.com/jerryjliu/llama_index.git`.\n",
      "\n",
      "2. Navigate to the downloaded repository using the command: `$ cd llama_index`.\n",
      "\n",
      "3. Go to the `examples/paul_graham_essay` folder using the command: `$ cd examples/paul_graham_essay`.\n",
      "\n",
      "4. Create a new Python file and import the necessary classes from LlamaIndex:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "```\n",
      "\n",
      "5. Load the documents that you want to index using the `SimpleDirectoryReader` class:\n",
      "\n",
      "```python\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "```\n",
      "\n",
      "6. Build the index using the `VectorStoreIndex` class:\n",
      "\n",
      "```python\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```\n",
      "\n",
      "7. You can now use the index to query the documents. For example:\n",
      "\n",
      "```python\n",
      "query_engine = index.as_query_engine()\n",
      "response = query_engine.query(\"What did the author do growing up?\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "This will return a response based on the query.\n",
      "\n",
      "Note: The above steps assume that you have already installed LlamaIndex and have the necessary data files in the `data` folder.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do i create an index? Write your answer using only code.\"\n",
    "existing_answer = \"\"\"To create an index using LlamaIndex, you need to follow these steps:\n",
    "\n",
    "1. Download the LlamaIndex repository by cloning it from GitHub using the command: `$ git clone https://github.com/jerryjliu/llama_index.git`.\n",
    "\n",
    "2. Navigate to the downloaded repository using the command: `$ cd llama_index`.\n",
    "\n",
    "3. Go to the `examples/paul_graham_essay` folder using the command: `$ cd examples/paul_graham_essay`.\n",
    "\n",
    "4. Create a new Python file and import the necessary classes from LlamaIndex:\n",
    "\n",
    "```python\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "```\n",
    "\n",
    "5. Load the documents that you want to index using the `SimpleDirectoryReader` class:\n",
    "\n",
    "```python\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "```\n",
    "\n",
    "6. Build the index using the `VectorStoreIndex` class:\n",
    "\n",
    "```python\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "```\n",
    "\n",
    "7. You can now use the index to query the documents. For example:\n",
    "\n",
    "```python\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "This will return a response based on the query.\n",
    "\n",
    "Note: The above steps assume that you have already installed LlamaIndex and have the necessary data files in the `data` folder.\n",
    "\"\"\"\n",
    "\n",
    "prompt = refine_template.format(context_msg=text, query_str=question, existing_answer=existing_answer)\n",
    "response = llm.complete(prompt)\n",
    "print(response.te)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:53:01.193628Z",
     "start_time": "2024-02-27T09:52:53.541940Z"
    }
   },
   "id": "2593b0994c349057",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an index using LlamaIndex, you need to follow these steps:\n",
      "\n",
      "1. Download the LlamaIndex repository by cloning it from GitHub using the command: `$ git clone https://github.com/jerryjliu/llama_index.git`.\n",
      "\n",
      "2. Navigate to the downloaded repository using the command: `$ cd llama_index`.\n",
      "\n",
      "3. Go to the `examples/paul_graham_essay` folder using the command: `$ cd examples/paul_graham_essay`.\n",
      "\n",
      "4. Create a new Python file and import the necessary classes from LlamaIndex:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "```\n",
      "\n",
      "5. Load the documents that you want to index using the `SimpleDirectoryReader` class:\n",
      "\n",
      "```python\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "```\n",
      "\n",
      "6. Build the index using the `VectorStoreIndex` class:\n",
      "\n",
      "```python\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```\n",
      "\n",
      "7. You can now use the index to query the documents. For example:\n",
      "\n",
      "```python\n",
      "query_engine = index.as_query_engine()\n",
      "response = query_engine.query(\"What did the author do growing up?\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "This will return a response based on the query.\n",
      "\n",
      "Note: The above steps assume that you have already installed LlamaIndex and have the necessary data files in the `data` folder.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T09:53:49.517819Z",
     "start_time": "2024-02-27T09:53:49.509482Z"
    }
   },
   "id": "8ab2c215ac3b3303",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3db8333659a04e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
